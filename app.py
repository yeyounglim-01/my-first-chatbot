import streamlit as st
import os
from openai import AzureOpenAI
from dotenv import load_dotenv

# 1. í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ (.env íŒŒì¼ì´ ê°™ì€ í´ë”ì— ìˆì–´ì•¼ í•¨)
load_dotenv()

st.title("ğŸ¤– ë‚˜ì˜ ì²« AI ì±—ë´‡")

# 2. Azure OpenAI í´ë¼ì´ì–¸íŠ¸ ì„¤ì •
# (ì‹¤ì œ ê°’ì€ .env íŒŒì¼ì´ë‚˜ ì—¬ê¸°ì— ì§ì ‘ ì…ë ¥í•˜ì„¸ìš”)
client = AzureOpenAI(
    api_key=os.getenv("AZURE_OAI_KEY"),
    api_version="2024-05-01-preview",
    azure_endpoint=os.getenv("AZURE_OAI_ENDPOINT")
)

# 3. ëŒ€í™”ê¸°ë¡(Session State) ì´ˆê¸°í™” - ì´ê²Œ ì—†ìœ¼ë©´ ìƒˆë¡œê³ ì¹¨ ë•Œë§ˆë‹¤ ëŒ€í™”ê°€ ë‚ ì•„ê°‘ë‹ˆë‹¤!
if "messages" not in st.session_state:
    st.session_state.messages = []

# 4. í™”ë©´ì— ê¸°ì¡´ ëŒ€í™” ë‚´ìš© ì¶œë ¥
for message in st.session_state.messages:
    with st.chat_message(message["role"]):
        st.markdown(message["content"])

# 5. ì‚¬ìš©ì ì…ë ¥ ë°›ê¸°
if prompt := st.chat_input("ë¬´ì—‡ì„ ë„ì™€ë“œë¦´ê¹Œìš”?"):
    # (1) ì‚¬ìš©ì ë©”ì‹œì§€ í™”ë©´ì— í‘œì‹œ & ì €ì¥
    st.chat_message("user").markdown(prompt)
    st.session_state.messages.append({"role": "user", "content": prompt})

    # (2) AI ì‘ë‹µ ìƒì„± (ìŠ¤íŠ¸ë¦¬ë° ë°©ì‹ ì•„ë‹˜, ë‹¨ìˆœ í˜¸ì¶œ ì˜ˆì‹œ)
    with st.chat_message("assistant"):
        response = client.chat.completions.create(
            model="gpt-4o-mini", # ì‚¬ìš©í•˜ì‹œëŠ” ë°°í¬ëª…(Deployment Name)ìœ¼ë¡œ ìˆ˜ì • í•„ìš”!
            messages=[
                {"role": m["role"], "content": m["content"]}
                for m in st.session_state.messages
            ]
        )
        assistant_reply = response.choices[0].message.content
        st.markdown(assistant_reply)

    # (3) AI ì‘ë‹µ ì €ì¥
    st.session_state.messages.append({"role": "assistant", "content": assistant_reply})
